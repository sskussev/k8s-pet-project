################################################################################################
Yandex Cloud
################################################################################################
id default vpc - enpjsbc3cataqv8p77fn
id subnet default a - default-ru-central1-a
cloud id - b1g597kc0l7coihmdlr7
folder id - b1gfgpm3lb7jnp83evv9

модуль https://github.com/terraform-yc-modules/terraform-yc-kubernetes

_____________Справка_____________

На мастер-ноде куба размещаются компоненты, управляющие кластером. Мастер обычно не используется для запуска пользовтельских подов (если только ты не отключишь соответствующую taint-метку, чего обычно не делают в продакшене. Исключение - миникуб - там и мастер и воркер нода это одна нода).

Основные компоненты на мастер-ноде:

kube-apiserver	- точка взаимодействия с кластером. Все команды kubectl, CI/CD, контроллеры и другие компоненты идут сюда, чтобы взаимодейтсовать с кластером и что то менять/узнавать.
etcd - key-value хранилище состояния кластера (конфигурация, статус, секреты, etc).
kube-scheduler - назначает поды на воркеры, исходя из ресурсов, taints, affinities и т.п.
kube-controller-manager	- эта штука запускает деплойменты, джобы и тд, типа движок программы (бэк) k8s
cloud-controller-manager - интегрирует кластер с облаком, чтобы при создании например nginx controllerа LB для него из облака подрубался сам и тд, диски облака монтирует в кубер (короче прослойка между кластером и машинами облачного провайдера)
может что то еще было, не помню

Воркер ноды - тут запускаются все пользовательские поды, базовые системные компоненты, нужные для работы этих подов.

компоненты: 

kubelet - управляет подами на ноде и общается с kube-apiserver, чтобы узнать что вообще надо поставить и тд, запускает контейнеры в подах через container runtime
kube-proxy	- взаимодейтсвет с iptables правилами для маршрутизации сервисов чтобы был сетевой доступ до подов, по сути смотрит в etcd через api и перепысывает iptables
container runtime - реда выполнения контейнеров (пример Docker или какая то другая контейнеризация) - запуск, остановка, перезапуск контейнеров в поде

Воркеры не хранят конфиг кластера
Всё в etcd через kube-apiserver

возможно есть что то еще - но это уже надо гуглить
____________________________________________________

################################################################################################
Terraform
################################################################################################
Ставим утилитку в которой можно выбирать версию терраформа которая будет активна 
brew install tfenv      
ставим версию в утилитку
tfenv install 1.10.3
активируем версию
tfenv use 1.10.3

_____________Справка_____________
Terrfaorm - позволяет описывать и управлять инфраструктурой (сервера, сети, базы, кластера куба) с помощью файлов .tf, как будто ты программируешь инфраструктуру
IaC - Infra as Code

Принцип работы
Ты пишешь конфигурацию в .tf файлах (например, создать куб в Yandex Cloud)
Terraform планирует изменения: сравнивает желаемое с текущим
Terraform применяет изменения: создаёт/обновляет/удаляет ресурсы через API облака (провайдер)

Основные команды
terraform init	подготавливает проект (скачивает провайдеры)
terraform plan	показывает, что будет создано/изменено
terraform apply	применяет изменения (создаёт ресурсы)
terraform destroy удаляет созданные ресурсы

Основные файлы
main.tf - основная конфигурация
variables.tf - переменные (обявление)
outputs.tf - что вернуть пользователю
versions.tf - для хранения требований к версиям Terraform и провайдеров.
terraform.tfvars - значения переменных

после init будет
.terraform/ — служебная директория - cодержит все внутренности Terraform, которые не стоит трогать
.terraform.lock.hcl — зависимости какие то - тоже не трогать
Это стоит коммитить в git, чтобы вся команда использовала одинаковые версии. Если команда использует локально терраформ, а не через CI

Провайдеры - это плагины, которые умеют управлять конкретными сервисами (Yandex, AWS, helm) в конкретных облаках

Команды для деплоя k8s:

terraform init 

terraform plan - смотрим что будет изменено

terraform apply (yes после проверки) - вносим изменения
